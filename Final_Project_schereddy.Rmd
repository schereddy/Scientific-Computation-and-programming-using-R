---
title: "Final Project for Scientific Computation and Programming: Sentimental analysis of Trip advisor reviews"
output: html_notebook
Name: Susmitha Chereddy
Email: schereddy2371@floridapoly.edu
---

Project description:

For this project, we are using the reviews data from Kaggle on Hilton Hawaiian Village Beach Resort located in Honolulu. Data has 13701 rows and 2 columns (review and review date). We will be using R Packages and functionalities to perform text mining and sentimental analysis on this data. Goal of this project is to perform text mining, analyze the words/ emotions contributing to the sentiment of the review and assign a sentiment to each review.


```{r}
# Reading all librraies

#library(dplyr)
#library(readr)
#library(lubridate)
#library(ggplot2)
#library(tidytext)
#library(tidyverse)
#library(stringr)
#library(tidyr)
#library(scales)
#library(broom)
#library(purrr)
#library(widyr)
#library(igraph)
#library(ggraph)
#library(SnowballC)
#library(wordcloud)
#library(reshape2)
#theme_set(theme_minimal())

```




```{r}
#data1 <- read_csv("C:/Users/schereddy/OneDrive/Documents/Engineering_Management/Scientific_Computing/project/Hilton_Hawaiian_Village_Waikiki_Beach_Resort-Honolulu_Oahu_Hawaii__en.csv/Hilton_Hawaiian_Village_Waikiki_Beach_Resort-Honolulu_Oahu_Hawaii__en.csv")
data1 <- data1[complete.cases(data1), ]
data1$review_date <- as.Date(data1$review_date, format = "%d-%B-%y")
dim(data1); min(data1$review_date); max(data1$review_date)
```
We see that there are 13701 reviews on TripAdvisor for Hilton Hawaiian Village hotel.The time period of this reviews is from 2002 to 2018 with a start date of 21st March 2002 and End date of 2nd August 2018.

```{r}
data1 %>% count(week = round_date(review_date, unit="week")) %>%
ggplot(aes(week, n)) +
geom_line(colour="#660099", size =0.60) +
ggtitle('Reviews by week')
```

Form the above distribution, we see that the highest numbers of reviews was in 2014 receiving almost more than 70 reviews in a week.

```{r}
data1 <- tibble::rowid_to_column(data1, "ID")

```


```{r}
data1 <- data1 %>%
  mutate(review_date = as.POSIXct(review_date, origin = "1970-01-01"),month = round_date(review_date, "month"))

reviewer_words <- data1 %>%
  distinct(review_body, .keep_all = TRUE) %>%
  unnest_tokens(word, review_body, drop = FALSE) %>%
  distinct(ID, word, .keep_all = TRUE) %>%
  anti_join(stop_words, by = "word") %>%
  filter(str_detect(word, "[^\\d]")) %>%
  group_by(word) %>%
  mutate(word_total = n()) %>%
  ungroup()

review_word_counts <- reviewer_words %>%
  count(word, sort = TRUE)

review_word_counts %>%
  head(25) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col(fill = "#660099") +
  scale_y_continuous(labels = comma_format()) +
  coord_flip() +
  labs(title = "Common words in the reviews",
       subtitle = "For all 13,701 reviews; after removing stop words",
       y = "Number of uses")
```

>> The above graph shows the distribution of most commonly used words after removing stopwords such as is,the,was,in,of,me,you,her,..etc. Full list of stopwords can be found at https://countwordsfree.com/stopwords 

>> we see that beach, hotel and tower are the most used reviews to mention ther experience about Hilton Hawaain Village.



```{r}
word_counts %>%
head(25) %>%
mutate(word = wordStem(word)) %>%
mutate(word = reorder(word, n)) %>%
ggplot(aes(word, n)) +
geom_col(fill = "#660099") +
scale_y_continuous(labels = comma_format()) +
coord_flip() +
labs(title = "Common words in reviews ",
subtitle = "For all 13,701 reviews; After stemming and removing stop words",
y = "Number of uses")

```

>> From the above graph we see the commonly used words after stemming them. Now both stay and stayed fall under stai by still retaining the menaning/sentiment for the word.

>> Some common examples of stemming is as below: {Played,plays,playing} can grouped under the stem "Play".


 

```{r}
library(widyr)
library(igraph)
library(ggraph)
```



>> Next let's look at how we can extend teh analysis to Bigrams. Words/meaning of the words often change when they are used together and hence it is essential to study bigrams. These are the set of words that appear together ine the text. Now, let's do a frequency analaysis on the bi-grams to see the frquently used bi-grams in the review-text. 

```{r}

bigrams_in_review <- data1 %>% unnest_tokens(bigram, review_body, token = "ngrams", n = 2)

separated_bigrams <- bigrams_in_review %>%
separate(bigram, c("word1", "word2"), sep = " ")

filtered_bigrams <- separated_bigrams %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)

count_bigrams <- filtered_bigrams %>%
count(word1, word2, sort = TRUE)

united_bigrams <- filtered_bigrams %>%
unite(bigram, word1, word2, sep = " ")

united_bigrams %>%
count(bigram, sort = TRUE)

```
>>  Forom the analysis we see that the most commonly used bi-grams are "rainbow tower" followed by "hawaiian village" and "hilton hawaiin"... 

>> Now, let's go ahead and visualize the bigrams.

```{r}
subject_review <- data1 %>%
unnest_tokens(word, review_body) %>%
anti_join(stop_words)

my_stopwords_list <- data_frame(word = c(as.character(1:10)))
subject_review <- subject_review %>%
anti_join(my_stopwords_list)

title_word_pair_list <- subject_review %>%
pairwise_count(word, ID, sort = TRUE, upper = FALSE)

set.seed(1234)
title_word_pair_list %>%
filter(n >= 1000) %>%
graph_from_data_frame() %>%
ggraph(layout = "fr") +
geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour =
"cyan4") +
geom_node_point(size = 5) +
geom_node_text(aes(label = name), repel = TRUE,
point.padding = unit(0.2, "lines")) +
ggtitle('Word network in TripAdvisor reviews')
theme_void()

```
>> The above graph visualizes the list of common bi-grams in the Trip advisor reviews that showed up atleast a thousand times with both the words not being a stopword.
>> Although we do not see that there is not a clear structre in the network, we see the most commonly used words here such as { beach, pool, hotel,ocean, hilton}


>> Now, let us look at trigrams to understand the review much better. Trigrams are the list of three words that coccur together in sentence.

```{r}

trigrams_review <- data1 %>%
unnest_tokens(trigram, review_body, token = "ngrams", n = 3)

separated_trigrams <- trigrams_review %>%
separate(trigram, c("word1", "word2", "word3"), sep = " ")

filtered_trigrams <- separated_trigrams %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word) %>%
filter(!word3 %in% stop_words$word)

count_trigram <- filtered_trigrams %>% 
  count(word1, word2, word3, sort = TRUE)

united_trigrams <- filtered_trigrams %>%
  unite(trigram, word1, word2, word3, sep = " ")

united_trigrams %>%
count(trigram, sort = TRUE)

```

>> After look at frequency counts of the trigrams, we see that the frequently used trigram is hilton hawaiian vilage which the name of the hotel itself followed by "diamond head tower" and "partial ocean view" which are probably used to describe the hotel.



>> Now let's try to answer some questions like what words have been increasing in frequency over the years and which words have been decresing in freqiency for the same time duration.



```{r}
per_month_reviews <- data1 %>%
  group_by(month) %>%
  summarize(month_total = n())

monthly_word_counts <- review_words %>%
filter(word_total >= 1000) %>%
count(word, month) %>%
complete(word, month, fill = list(n = 0)) %>%
inner_join(per_month_reviews, by = "month") %>%
mutate(percent = n / month_total) %>%
mutate(year = year(month) + yday(month) / 365)

mod_1 <- ~ glm(cbind(n, month_total - n) ~ year, ., family = "binomial")


```



```{r}

slopes_mod <- monthly_word_counts %>%
nest(data = -word) %>%
mutate(model = map(data, mod_1),
model = map(model,tidy)) %>%
unnest(model) %>%
filter(term == 'year') %>%
arrange(desc(estimate))

slopes_mod %>%
head(9) %>%
inner_join(monthly_word_counts, by = "word") %>%
mutate(word = reorder(word, -estimate)) %>%
ggplot(aes(month, n / month_total, color = word)) +
geom_line(show.legend = FALSE) +
scale_y_continuous(labels = percent_format()) +
facet_wrap(~ word, scales = "free_y") +
expand_limits(y = 0) +
labs(x = "Year",
y = "% of reviews that contain this word",
title = "Top Nine fastest growing words in TripAdvisor reviews",
subtitle = "Analyzed by growth rate over 15 years")

```

 >> FRom the graph, we  can see that words like fireworks, lagoon and friday grew from 2010. On the other hand words like words like resort and busy had a healthly growth between 2005 and 2010.


```{r}
slopes_mod %>%
  tail(9) %>%
  inner_join(monthly_word_counts, by = "word") %>%
  mutate(word = reorder(word, estimate)) %>%
  ggplot(aes(month, n / month_total, color = word)) +
  geom_line(show.legend = FALSE) +
  scale_y_continuous(labels = percent_format()) +
  facet_wrap(~ word, scales = "free_y") +
  expand_limits(y = 0) +
  labs(x = "Year",
       y = "% of reviews containing this term",
       title = "Top Nine fastest shrinking words in TripAdvisor reviews",
       subtitle = "Analyzed by growth rate over 15 years")
```

>> From the above graph, we see that words like hhv are in clear decsreaing trend from 2005. It says that people have stopped mentioning shortcut name for hilton hawaiin village.Also, words like breakfast, coffee,upgrdaes and store have also been on the decresing trend.


```{r}
monthly_word_counts %>%
  filter(word %in% c("recommend", "beautiful")) %>%
  ggplot(aes(month, n / month_total, color = word)) +
  geom_line(size = 0.5, alpha = .9) +
  scale_y_continuous(labels = percent_format()) +
  expand_limits(y = 0) +
  labs(x = "Year",
       y = "% of reviews containing this term", title = "recommend vs beautiful in terms of reviewers interest")
```

>> we see that both the words were heavily used before 2005 and their trend started to decrease from 2005. This tells us that users started avoiding words like beautiful and recommend on the reviews.



>> Now, let's perform sentimental analysis to see which words are contributing to postivie sentiment and which words are contributing to negative snetiment.

```{r}
reviews <- data1 %>% 
  filter(!is.na(review_body)) %>% 
  select(ID, review_body) %>% 
  group_by(row_number()) %>% 
  ungroup()

reviews_tidy <- reviews %>%
  unnest_tokens(word, review_body)

reviews_tidy <- reviews_tidy %>%
  anti_join(stop_words)
#reviews_tidy

word_counts_bing <- reviews_tidy %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

word_counts_bing %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free") +
  labs(y = "Contribution to sentiment", x = NULL) +
  coord_flip() + 
  ggtitle('positive and negative sentiment contribution form words in the reviews')

```

>> From the above chart, we see that most of the negative words like expensive,crowded,bad and complex are grouped under negative sentiment while words like nice, clean, beautiful and friendly are marked as positive.


>> Let's try another popular lexicon used for sentimental analysis AFINN deveoped by Finn Arip Neilsen. This is a repository of 3300+ words with polarity assigned to them to analyze if tend to lean positive / negative.

```{r}
afinn_contributions <- reviews_tidy %>%
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(word) %>%
  summarize(occurences = n(),
            contribution = sum(value))

afinn_contributions %>%
  top_n(25, abs(contribution)) %>%
  mutate(word = reorder(word, contribution)) %>%
  ggplot(aes(word, contribution, fill = contribution > 0)) +
  ggtitle('Words with the greatest contributions to positive/negative 
          sentiment in reviews') +
  geom_col(show.legend = FALSE) +
  coord_flip()

```
>> here we see a lot less words contributed under negative while a lot of adjectives like nice, beautiful,amazing have been marked as positive sentiment. Problem with this kind of sentiment is that they can quickly change the snetiment when thay are preceeded by a not. Hence we need to consider this bigram analysis using not as assign appropriate sentiment.


```{r}
separated_bigrams %>%
  filter(word1 == "not") %>%
  count(word1, word2, sort = TRUE)

```

In the data, the word "a" was preceded by the word "not" 850 times, while the word "the" was preceded by the word "not" 698 times. But, This data is not meaningful.


```{r}
AFINN <- get_sentiments("afinn")
words_with_not <- bigrams_separated %>%
  filter(word1 == "not") %>%
  inner_join(AFINN, by = c(word2 = "word")) %>%
  count(word2, value, sort = TRUE) %>%
  ungroup()
words_with_not
```

Here we see that words like worth and recommend that have a positive sentiment score. But, when these are combined with not, they tend to become a negative sentiment.

Now let's take a look at all the words that contributed in the opposite direction.


```{r}
words_with_not %>%
  mutate(contribution = n * value) %>%
  arrange(desc(abs(contribution))) %>%
  head(20) %>%
  mutate(word2 = reorder(word2, contribution)) %>%
  ggplot(aes(word2, n * value, fill = n * value > 0)) +
  geom_col(show.legend = FALSE) +
  xlab("Words with \"not\" in front") +
  ylab("Sentiment value * number of occurrences") +
  ggtitle('Top 20 words with \"not\" that contributed either in positive/negative direction') +
  coord_flip()
```




```{r}
negative_words <- c("not", "no", "never", "without")

words_negated <- separated_bigrams %>%
  filter(word1 %in% negative_words) %>%
  inner_join(AFINN, by = c(word2 = "word")) %>%
  count(word1, word2, value, sort = TRUE) %>%
  ungroup()

words_negated %>%
  mutate(contribution = n * value,
         word2 = reorder(paste(word2, word1, sep = "__"), contribution)) %>%
  group_by(word1) %>%
  top_n(12, abs(contribution)) %>%
  ggplot(aes(word2, contribution, fill = n * value > 0)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ word1, scales = "free") +
  scale_x_discrete(labels = function(x) gsub("__.+$", "", x)) +
  xlab("Words preceded by negative term") +
  ylab("Sentiment value * Number of occurrences") +
  ggtitle('Common words with positive/negative sentiment associate with negation words like : No,Not,Never,Without"') +
  coord_flip()

```

>> Now let's find out reviews with highest negative or postive sentiment.


```{r}
messages_sentiment <- reviews_tidy %>%
  inner_join(get_sentiments("afinn"), by = "word") %>%
  group_by(ID) %>%
  summarize(sentiment = mean(value),
            words = n()) %>%
  ungroup() %>%
  filter(words >= 5)

messages_sentiment %>%
  arrange(desc(sentiment))

```

>> The most positive review in our data is with ID 2363. Now, let's look at the review to see if the sentiment makes sense.

```{r}
data1[ which(data1$ID==2363), ]$review_body[1]
```
This looks like a pretty happy review and definitely a positive one. Let's look at another one.


```{r}
data1[ which(data1$ID==2578), ]$review_body[1]
```
>> This sounds positive too!!


Now let's look at the reviews that had the highest negative sentiment. We see that the review 3748 had the high negative sentiment.  
```{r}
messages_sentiment %>%
  arrange(sentiment)
```


Let's look at the review to see if it actually negative.

```{r}
data1[ which(data1$ID==3748), ]$review_body[1]
```

Let's look at a few more.

```{r}
data1[ which(data1$ID==317), ]$review_body[1]
```

```{r}
data1[ which(data1$ID==7135), ]$review_body[1]
```

>>References:

P. Andersen, What Is Web 2.0? Ideas, Technologies and Implications for Education, tech. report, JISC Technology & Standards Watch, 2007; www.ictliteracy .info/rf.pdf/Web2.0_research.pdf.

E. Cambria, “Affective Computing and Sentiment Analysis,” IEEE Intelligent Systems, vol. 31, no. 2, 2016, pp. 102–107.

B. Liu, Sentiment Analysis: Mining Opinions, Sentiments, and Emotions, Cambridge Univ. Press, 2015.

World Travel and Tourism Council, Travel & Tourism Economic Impart 2016 World, 2016; www.wttc.org//media/files/reports/economic%20 impact%20research/regions%202016/world2016.pdf.\

J. Serrano-Guerrero et al., “Sentiment Analysis: A Review and Comparative Analysis of Web Services,” Information Science, vol. 311, Aug. 2015, pp. 18–38.

E. Cambria and A. Hussain, Sentic Computing: A Common-Sense-Based Framework for ConceptLevel Sentiment Analysis, Springer, 2015.

F.H. Khan, S. Bashir, and U. Qamar, “TOM: Twitter Opinion Mining Framework Using Hybrid Classification Scheme,” Decision Support Systems, vol. 57, Jan. 2014, pp. 245–257.

E. Guzman and W. Maalej, “How Do Users Like This Feature? AFine Grained Sentiment Analysis of App Reviews,” Proc. IEEE 22nd Int’l Conf. Requirements Eng., 2014, pp. 153–162.

D. Gräbner et al., “Classification of Customer Reviews based on Sentiment Analysis,” Information and Comm. Technologies in Tourism, Springer, 2012, pp. 460–470.

S. Palakvangsa-Na-Ayudhya et al., “Nebular: A Sentiment Classification System for the Tourism Business,” Proc. 8th Int’l Joint Conf. Computer Science and Software Eng., 2011, pp. 293–298.

K. Ilieska, "Customer satisfaction index-as a base for strategic marketing management", TEM Journal, vol. 2, no. 4, pp. 327, 2013.

Abdullah, T. (2017). Penilaian Wisatawan akan Atribut Pariwisata di Kota Batu. THE Journal : Tourism and Hospitality Essentials Journal, 7(2), 91.

Bandur, A. (2016). Penelitian Kualitatif : Metodologi, Desain, dan Teknik Analisis Data Dengan Nvivo 11 Plus (1st ed.; Jatmiko, ed.). Jakarta: Mitra Wacana Media.

Web Scraping TripAdvisor, Text Mining and Sentiment Analysis for Hotel Reviews | by Susan Li | Towards Data Science

Real-time Hand Gesture Recognition using TensorFlow & OpenCV - TechVidvan

Fast-Tracking Hand Gesture Recognition AI Applications with Pretrained Models from NGC | NVIDIA Technical Blog

M. Hu and B. Liu, “Mining and Summarizing Customer Reviews,” Proc. 10th ACM SIGKDD Int’l Conf. Knowledge Discovery and Data Mining, 2004, pp. 168–177.

K. Shouten and F. Frasincar, “Survey on AspectLevel Sentiment Analysis,” IEEE Trans. Knowledge and Data Eng., vol. 28, March 2016, pp. 813–830.

M. Atzmueller, “Subgroup Discovery,” Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, vol. 5, no. 1, 2015, pp. 35-49.

S. Poria et al., “A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks,” Proc. 26th Int’l Conf. Computational Linguistics (COLING16), 2016, pp. 1601–1612.

F. Herrera et al., Multiple Instance Learning: Foundations and Algorithms, Springer, 2016.

>>Supplementary material:

https://www.kaggle.com/code/kerneler/starterhilton-hawaiian-village-048bdbd4-9/data

https://www.kaggle.com/datasets/andrewmvd/trip-advisor-hotel-reviews

https://www.kaggle.com/code/wiktorbrk/tripadvisor-reviews-sentiment-analysis

https://www.kaggle.com/code/frankschindler1/sentiment-analysis-tripadvisor-reviews

https://www.kaggle.com/code/mmaguero/tripadvisor-sentiment-analysis-for-hotel-reviews/output

https://www.kaggle.com/code/wiktorbrk/tripadvisor-reviews-sentiment-analysis/comments

https://www.kaggle.com/code/mmaguero/tripadvisor-sentiment-analysis-for-hotelreviews/comments

https://www.kaggle.com/questions-andanswers/142233

https://www.kaggle.com/code/jonathanoheix/sentiment-analysis-with-hotel-review


